from tqdm import tqdm
import numpy as np
import time
import math
import scipy
import scipy.stats
import copy
from recurrent_rsa.rsa_utils.config import *
from recurrent_rsa.bayesian_agents.rsaState import RSA_State
from recurrent_rsa.bayesian_agents.rsaWorld import RSA_World
from recurrent_rsa.rsa_utils.image_and_text_utils import max_sentence_length, index_to_char, char_to_index, devectorize_caption, \
    sentence_likelihood, largest_indices, vectorize_caption

###
"""
Recursion schemes for the RSA
"""


###

# you should call this so that running unroll beam prints this out
# calculates likelihood of caption being generated by a speaker
def likelihood(self, depth=0, which_image=0, speaker_rationality=1.0, speaker=0, listener_rationality=1.0,
               img_prior=np.log(np.asarray([0.5, 0.5])), start_from=""):
    self.speaker_rationality = speaker_rationality
    self.listener_rationality = listener_rationality
    self.image_priors = np.log(np.ones((max_sentence_length + 1, self.images.shape[0])) * (1 / self.images.shape[0]))
    self.image_priors[0] = img_prior
    sentence = np.expand_dims(np.expand_dims(vectorize_caption(start_from)[0], 0), -1)
    self.context_sentence = copy.deepcopy(sentence)

    likelihood = {}

    for i in range(1, max_sentence_length):
        self.i = i
        char = np.squeeze(sentence)[i]
        s = np.squeeze(self.speaker(img_idx=which_image, depth=depth))
        likelihood[i] = s[char]
        if index_to_char[char] == stop_token:
            break

    print(start_from, np.prod([np.exp(p) for (l, p) in likelihood.items()]))


def ana_greedy(rsa, initial_world_prior, speaker_rationality, speaker, target, pass_prior=True,
               listener_rationality=1.0, depth=0, start_from=[]):
    """
	speaker_rationality,listener_rationality:

		see speaker and listener code for what they do: control strength of conditioning

	depth:

		the number of levels of RSA: depth 0 uses listeral speaker to unroll, depth n uses speaker n to unroll, and listener n to update at each step

	start_from:

		a partial caption you start the unrolling from

	img_prior:

		a prior on the world to start with
	"""

    # this RSA passes along a state: see rsa_state
    state = RSA_State(initial_world_prior, listener_rationality=listener_rationality)
    # state.image_priors[:]=img_prior

    context_sentence = ['^'] + start_from
    state.context_sentence = context_sentence

    world = RSA_World(target=target, rationality=speaker_rationality, speaker=speaker)

    probs = []
    for timestep in tqdm(range(len(start_from) + 1, max_sentence_length)):

        state.timestep = timestep
        s = rsa.speaker(state=state, world=world, depth=depth)
        # print("S:",s)
        # print(s)
        segment = np.argmax(s)
        # print("s",rsa.idx2seg[segment])
        prob = np.max(s)
        probs.append(prob)

        if pass_prior:
            l = rsa.listener(state=state, utterance=segment, depth=depth)
            state.world_priors[state.timestep] = l
        state.context_sentence += [rsa.idx2seg[segment]]
        if (rsa.idx2seg[segment] == stop_token[rsa.seg_type]):
            break

    summed_probs = np.sum(np.asarray(probs))

    world_posterior = state.world_priors[:state.timestep + 1][:5]

    return [("".join(state.context_sentence), summed_probs)]


# But within the n-th order ethno-metapragmatic perspective, this creative indexical effect is the motivated realization, or performable execution, of an already constituted framework of semiotic value.
def ana_beam(rsa, initial_world_prior, speaker_rationality, target, speaker, pass_prior=True, listener_rationality=1.0,
             depth=0, start_from=[], beam_width=len(sym_set), cut_rate=1, decay_rate=0.0, beam_decay=0, ):
    print("beam_width", beam_width)
    """
	speaker_rationality,listener_rationality:

		see speaker and listener code for what they do: control strength of conditioning

	depth:

		the number of levels of RSA: depth 0 uses listeral speaker to unroll, depth n uses speaker n to unroll, and listener n to update at each step

	start_from:
		a partial caption you start the unrolling from
	img_prior:
		a prior on the world to start with
	which_image:
		which of the images in the prior should be targeted?
	beam width: width beam is cut down to every cut_rate iterations of the unrolling
	cut_rate: how often beam is cut down to beam_width
	beam_decay: amount by which beam_width is lessened after each iteration
	decay_rate: a multiplier that makes later decisions in the unrolling matter less: 0.0 does no decay. negative decay makes start matter more
	"""

    state = RSA_State(initial_world_prior, listener_rationality=listener_rationality)
    # state.image_priors[:]=img_prior

    context_sentence = start_from
    state.context_sentence = context_sentence

    world = RSA_World(target=target, rationality=speaker_rationality, speaker=speaker)

    context_sentence = start_from
    state.context_sentence = context_sentence

    sent_worldprior_prob = [(state.context_sentence, state.world_priors, 0.0)]

    final_sentences = []

    toc = time.time()
    for timestep in tqdm(range(len(start_from) + 1, max_sentence_length)):

        state.timestep = timestep

        new_sent_worldprior_prob = []
        for sent, worldpriors, old_prob in sent_worldprior_prob:

            state.world_priors = worldpriors

            if state.timestep > 1:

                state.context_sentence = sent[:-1]
                seg = sent[-1]

                if depth > 0 and pass_prior:
                    l = rsa.listener(state=state, utterance=rsa.seg2idx[seg], depth=depth)
                    state.world_priors[state.timestep - 1] = copy.deepcopy(l)

            state.context_sentence = sent

            # out = rsa.speaker(state=state,img_idx=which_image,depth=depth)
            s = rsa.speaker(state=state, world=world, depth=depth)

            for seg, prob in enumerate(np.squeeze(s)):
                new_sentence = copy.deepcopy(sent)

                # conditional to deal with captions longer than max sentence length
                # if state.timestep<max_sentence_length+1:
                new_sentence += [rsa.idx2seg[seg]]
                # else: new_sentence = np.expand_dims(np.expand_dims(np.concat([np.squeeze(new_sentence)[:-1],[seg]],axis=0),0),-1)

                state.context_sentence = new_sentence

                new_prob = (prob * (1 / math.pow(state.timestep, decay_rate))) + old_prob

                # print("beam listener",rsa.word2ord[seg], l)

                new_sent_worldprior_prob.append((new_sentence, worldpriors, new_prob))

        rsa.flush_cache()
        sent_worldprior_prob = sorted(new_sent_worldprior_prob, key=lambda x: x[-1], reverse=True)

        if state.timestep % cut_rate == 0:
            # cut down to size
            sent_worldprior_prob = sent_worldprior_prob[:beam_width]
            new_sent_worldprior_prob = []

            for sent, worldprior, prob in sent_worldprior_prob:
                # print("".join(sent),np.exp(prob))
                # print(state.timestep)
                if sent[-1] == stop_token[rsa.seg_type]:
                    final_sentence = copy.deepcopy(sent)
                    final_sentences.append((final_sentence, prob))
                # print("REMOVED SENTENCE")
                else:
                    new_triple = copy.deepcopy((sent, worldprior, prob))
                    new_sent_worldprior_prob.append(new_triple)

            sent_worldprior_prob = new_sent_worldprior_prob

            if len(final_sentences) >= 50:
                # 	# print("beam unroll time",tic-toc)
                # 	# print(state.image_priors[:])
                sentences = sorted(final_sentences, key=lambda x: x[-1], reverse=True)
                output = []
                for i, (sent, prob) in enumerate(sentences):
                    output.append(("".join(sent), prob))

                return output
        # 		# print(sentences)
        # 		for i,(sent,prob) in enumerate(sentences):

        # 			output.append(("".join([rsa.idx2word[idx] for idx in np.squeeze(sent)]),prob))

        # 		return output
        # 	return "COMPLETE"
        # 	return "".join([rsa.idx2word[idx] for idx in np.squeeze(final_sentences[0])])

        if beam_decay < beam_width:
            beam_width -= beam_decay
    # print("decayed beam width by "+str(beam_decay)+"; beam_width now: "+str(beam_width))

    else:
        sentences = sorted(final_sentences, key=lambda x: x[-1], reverse=True)

        output = []
        # print(sentences)
        for i, (sent, prob) in enumerate(sentences):
            output.append(("".join(sent), prob))

        return output
